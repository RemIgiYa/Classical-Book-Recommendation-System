{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TopicModeling/clustering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0H-t0FRhueu"
      },
      "source": [
        "#this line is needed when running the code in Google Colab because otherwise some packages won't work\n",
        "system2('sudo', 'apt-get install libgsl0-dev')\n",
        "\n",
        "install.packages(\"data.table\")\n",
        "install.packages(\"tm\")\n",
        "install.packages(\"topicmodels\")\n",
        "install.packages(\"tidytext\")\n",
        "install.packages(\"gutenbergr\")\n",
        "install.packages(\"reshape2\")\n",
        "install.packages(\"factoextra\")\n",
        "install.packages(\"kohonen\")\n",
        "library(gutenbergr)\n",
        "library(curl)\n",
        "library(dplyr)\n",
        "library(ggplot2)\n",
        "library(data.table)\n",
        "library(tm)\n",
        "library(topicmodels)\n",
        "library(tidytext)\n",
        "library(tidyr)\n",
        "library(stringr)\n",
        "library(scales)\n",
        "library(reshape2)\n",
        "library(rmarkdown)\n",
        "library(tidyverse)\n",
        "library(factoextra)\n",
        "library(kohonen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR17S6ErBFRs"
      },
      "source": [
        "#getting the classical books from gutenbergr package\n",
        "gutdata <- gutenberg_works()\n",
        "\n",
        "gutData <- gutdata[!is.na(gutdata$title),]\n",
        "\n",
        "subData <- gutenberg_subjects\n",
        "\n",
        "subData <- subData[!(subData$subject_type==\"lcc\"),]\n",
        "\n",
        "subData <- as.data.table(subData)[, toString(subject), by = list(gutenberg_id, subject_type)]\n",
        "\n",
        "#just the books that are fictional by subject\n",
        "ficBooks <- dplyr::filter(subData, grepl('fiction|Fiction|fantasy|Adventure|Fables|Fairy tales', V1))\n",
        "\n",
        "ficBooksExtra <- merge(x=gutData, y=ficBooks, by = \"gutenberg_id\", all.y=TRUE)\n",
        "\n",
        "ficBooksExtra <- ficBooksExtra[!is.na(ficBooksExtra$title),]\n",
        "\n",
        "subData <- dplyr::filter(subData, !grepl('fiction|Fiction|fantasy|Adventure|Fables|Fairy tales', V1))\n",
        "\n",
        "#13k records, the main list of all the fictional classical books from gutenbergr website\n",
        "write.csv(ficBooksExtra,'fictionalBooks.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PagWekrj-ll5"
      },
      "source": [
        "#taking a random sample of books from the main classical books dataset.\n",
        "#more than 1 thousand books are selected to account for occasional errors when downloading the book text. \n",
        "fictionalBooksP1<-read.csv(\"fictionalBooks.csv\")\n",
        "sample <- sample_n(fictionalBooksP1, 1100)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpLbnC1USRF_"
      },
      "source": [
        "#downloading the classical book text for all of the books within the 'sample' dataset\n",
        "bookText = data.frame()\n",
        "\n",
        "for (i in 1:dim(sample)[1]){\n",
        "  bookText <- rbind(bookText, gutenberg_download(sample$gutenberg_id[i], meta_fields = \"title\", mirror = \"http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/\"))\n",
        "}\n",
        "\n",
        "write.csv(bookText, 'bookText.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_HnmEY51Hke"
      },
      "source": [
        "#common names dataset which is used for removing majority of the names along with stopwords\n",
        "names <- read.csv(\"names.csv\")\n",
        "names$name <- tolower(names$name)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mek4SXkQ8jnb"
      },
      "source": [
        "#the dataset of additional stopwords to be removed\n",
        "additionalWords <- read.csv(\"AdditionalWordsToRemove.csv\")\n",
        "\n",
        "additionalWords$Words <- tolower(additionalWords$Words)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0I9D0jpifml"
      },
      "source": [
        "#going through the book text, removing the stopwords and names, splitting the text into single words\n",
        "\n",
        "bookText <- read.csv(\"bookText.csv\")\n",
        "\n",
        "by_chapter <- bookText %>%\n",
        "  group_by(title) %>%\n",
        "  mutate(chapter = cumsum(str_detect(\n",
        "    text, regex(\"^chapter \", ignore_case = TRUE)\n",
        "  ))) %>%\n",
        "  ungroup()\n",
        "\n",
        "# split into words\n",
        "by_chapter_word <- by_chapter %>%\n",
        "  unnest_tokens(word, text)\n",
        "\n",
        "# find document-word counts\n",
        "word_counts <- by_chapter_word %>%\n",
        "  filter(!word %in% c(stop_words$word, names$name, additionalWords$Words)) %>%\n",
        "  count(title, word, sort = TRUE) %>%\n",
        "  ungroup()\n",
        "\n",
        "word_counts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMlbRJD21s_e"
      },
      "source": [
        "#TF-IDF scores, removing words below the average score\n",
        "word_counts = word_counts %>% bind_tf_idf(word, title, n) %>%\n",
        "  arrange(desc(tf_idf))\n",
        "\n",
        "avg = mean(word_counts$tf_idf)\n",
        "\n",
        "word_counts = subset(word_counts, tf_idf>avg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRPoX2V7RMfg"
      },
      "source": [
        "#reducing the sample book list to one thousand. Initially more than one thousand were selected to account for occasional errors when downloading the text of some of the books.\n",
        "#having a number such as 100 or 1000 makes it easier to later set up correctly-sized SOM grid\n",
        "BookList <- as.data.frame(unique(word_counts$title))\n",
        "names(BookList)[1] <- \"title\"\n",
        "\n",
        "BookList <- sample_n(BookList, 1000)\n",
        "\n",
        "word_counts <- merge(x=word_counts, y=BookList, by = \"title\", all.y=TRUE)\n",
        "\n",
        "write.csv(word_counts,'ClassicalBookWordcounts.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsUO0s_uQRMu"
      },
      "source": [
        "#used for K-means and SOM, just a list of all the books used for the analysis\n",
        "documents <- as.data.table(unique(word_counts$title))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpd5YbUo1nBe"
      },
      "source": [
        "#dtm (document term matrix)\n",
        "chapters_dtm <- word_counts %>%\n",
        "  cast_dtm(title, word, n)\n",
        "\n",
        "chapters_dtm\n",
        "\n",
        "m2 <- as.matrix(chapters_dtm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3yZVEMvPmNp"
      },
      "source": [
        "LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rmWh_YB1qB8"
      },
      "source": [
        "chapters_lda <- LDA(chapters_dtm, k = 9, control = list(seed = 12))\n",
        "chapters_lda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5ErrBOGvn3Z"
      },
      "source": [
        "Visualisation for top N words for each topic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS6t_AEW-f3C"
      },
      "source": [
        "chapter_topics <- tidy(chapters_lda, matrix = \"beta\")\n",
        "chapter_topics\n",
        "\n",
        "write.csv(chapter_topics,'ClassicalBookWordsforTopics.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5TE0ZM7OXBi"
      },
      "source": [
        "top_terms <- chapter_topics %>%\n",
        "  group_by(topic) %>%\n",
        "  top_n(5, beta) %>%\n",
        "  ungroup() %>%\n",
        "  arrange(topic, -beta)\n",
        "\n",
        "top_terms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbceaT-R_BR9"
      },
      "source": [
        "write.csv(top_terms,'ClassicalBookTopTermsByTopic.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjraBlG7-jKV"
      },
      "source": [
        "png(file=\"1.1.png\" ,width=4000,height=4000, res = 300, bg=\"white\")\n",
        "top_terms %>%\n",
        "  mutate(term = reorder_within(term, beta, topic)) %>%\n",
        "  ggplot(aes(beta, term, fill = factor(topic))) +\n",
        "  geom_col(show.legend = FALSE) +\n",
        "  facet_wrap(~ topic, scales = \"free\") +\n",
        "  scale_y_reordered()\n",
        "dev.off()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQMBvUhKPwQu"
      },
      "source": [
        "Assigning a topic for each of the books."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY69YfPB-wCT"
      },
      "source": [
        "chapters_gamma <- tidy(chapters_lda, matrix = \"gamma\")\n",
        "chapters_gamma\n",
        "\n",
        "\n",
        "chapters_gamma <- chapters_gamma %>%\n",
        "  separate(document, c(\"title\", \"chapter\"), sep = \"_\", convert = TRUE)\n",
        "\n",
        "chapters_gamma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiZervWC-6vq"
      },
      "source": [
        "chapter_classifications <- chapters_gamma %>%\n",
        "  group_by(title, chapter) %>%\n",
        "  slice_max(gamma) %>%\n",
        "  ungroup()\n",
        "\n",
        "chapter_classifications"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrYfFSlQ_BP3"
      },
      "source": [
        "book_topics <- chapter_classifications %>%\n",
        "  count(title, topic) %>%\n",
        "  group_by(title) %>%\n",
        "  top_n(1, n) %>%\n",
        "  ungroup() %>%\n",
        "  transmute(consensus = title, topic)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qpk3DHLFwfd7"
      },
      "source": [
        "names(book_topics)[1] <- \"title\"\n",
        "names(book_topics)[2] <- \"LDAtopics\"\n",
        "\n",
        "write.csv(book_topics, 'LDAtopics.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2qY6Ya8IHE4"
      },
      "source": [
        "K-means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiD-jT4kf24r"
      },
      "source": [
        "set.seed(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgmgAPNYQc95"
      },
      "source": [
        "kmBooks2 <- scale(m2)\n",
        "head(kmBooks2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOE6PpJoQkup"
      },
      "source": [
        "kBmean <- kmeans(kmBooks2, centers=9, nstart=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a2-_rg0Qm78"
      },
      "source": [
        "kBmean$cluster"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtMf2UhyQtrY"
      },
      "source": [
        "Kclusters <- documents %>%\n",
        "  mutate(Cluster = kBmean$cluster) %>%\n",
        "  group_by(Cluster)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ1rMPSvGE9t"
      },
      "source": [
        "Kclusters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmHZsFh6Qwwk"
      },
      "source": [
        "names(Kclusters)[1] <- \"title\"\n",
        "names(Kclusters)[2] <- \"KmeansClusters\"\n",
        "\n",
        "write.csv(Kclusters, 'K-meansClusters.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td9K9hyVQ1tn"
      },
      "source": [
        "Some visualisations for seeing how the clusters (at different values) are distributed. Only suitable for small amounts of data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82Yv18mhQpjg"
      },
      "source": [
        "fviz_cluster(kBmean, data = kmBooks2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMfezpUZISxn"
      },
      "source": [
        "k2 <- kmeans(kmBooks2, centers = 9, nstart = 25)\n",
        "k3 <- kmeans(kmBooks2, centers = 6, nstart = 25)\n",
        "k4 <- kmeans(kmBooks2, centers = 3, nstart = 25)\n",
        "k5 <- kmeans(kmBooks2, centers = 12, nstart = 25)\n",
        "\n",
        "# plots to compare\n",
        "p1 <- fviz_cluster(k2, geom = \"point\", data = kmBooks2) + ggtitle(\"k = 9\")\n",
        "p2 <- fviz_cluster(k3, geom = \"point\",  data = kmBooks2) + ggtitle(\"k = 6\")\n",
        "p3 <- fviz_cluster(k4, geom = \"point\",  data = kmBooks2) + ggtitle(\"k = 3\")\n",
        "p4 <- fviz_cluster(k5, geom = \"point\",  data = kmBooks2) + ggtitle(\"k = 12\")\n",
        "\n",
        "\n",
        "png(file=\"1.png\" ,width=4000,height=4000, res = 300, bg=\"white\")\n",
        "grid.arrange(p1, p2, p3, p4, nrow = 2)\n",
        "dev.off()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAJkqENeRAK7"
      },
      "source": [
        "SOM (Self Organising Maps)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-DHZwiAnlDV"
      },
      "source": [
        "#creates a grid for 100 x 10 books (1000); if a different sample size is used, the grid size should be adjusted to match it\n",
        "som.grid <- somgrid(xdim = 100, ydim = 10, topo = 'hexagonal')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdGqURnMzhoN"
      },
      "source": [
        "som.model <- som(data.matrix(m2), grid = som.grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb3PocApm8y1"
      },
      "source": [
        "som.events <- som.model$codes[[1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9Cm_EZfzkjI"
      },
      "source": [
        "#post SOM processing\n",
        "clusters <- kmeans(som.events, centers = 9, iter.max = 100, nstart = 10)$cluster"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmKTM8rf1s5P"
      },
      "source": [
        "clustersSOM <- documents %>%\n",
        "  mutate(ClusterSOM = clusters) %>%\n",
        "  group_by(ClusterSOM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAu60x6t1v9U"
      },
      "source": [
        "names(clustersSOM)[1] <- \"title\"\n",
        "names(clustersSOM)[2] <- \"SOMclusters\"\n",
        "\n",
        "\n",
        "write.csv(clustersSOM, 'SOMClusters.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyIft-QF1yWz"
      },
      "source": [
        "Visuals that may not be suitable for large data samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPl-_dPi13dN"
      },
      "source": [
        "plot(som.model, type=\"changes\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR3XHkG815Ky"
      },
      "source": [
        "plot(som.model, type=\"count\", main=\"Node Counts\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M2AZfqf16k_"
      },
      "source": [
        "# U-matrix visualisation\n",
        "plot(som.model, type=\"dist.neighbours\", main = \"SOM neighbour distances\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}